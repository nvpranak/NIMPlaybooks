{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7367f384-c915-44c1-8e1a-531a79c0520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "import getpass\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0882eea4-48bc-4643-8d67-855c9e527acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-***************************************************'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396df79-67d5-4ad3-95bf-09f07dce8c58",
   "metadata": {},
   "source": [
    "## Load documents by scraping the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715c3c3f-f203-47a0-903f-e7f952964dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    # Load, chunk and index the contents of the blog.\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(\n",
    "                class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a7af70-2763-4f04-a30d-7862eee00c09",
   "metadata": {},
   "source": [
    "## Format docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6ca055-e40d-43cf-a558-2572add0f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad437aea-8c60-4f1c-99c9-4bc10e0acf59",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69bfa5f1-cfb1-4d17-9afb-c476a9b2d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494254e-65a2-4f44-a2e7-a7cd4509faf7",
   "metadata": {},
   "source": [
    "## Vectorstore and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97813fba-e2c9-4819-9587-551fd4ae211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = load_documents()\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a750b0-a8d4-4a3d-b87c-1f8f04d94013",
   "metadata": {},
   "source": [
    "## Custom RAG prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb84e8b3-f6bb-4219-8553-c87ec72037c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438ad864-6b50-467e-a57c-575d79383ba9",
   "metadata": {},
   "source": [
    "## RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3794e20-6616-4589-ab57-4aae357beae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37add245-59e9-4dd0-82b7-1f6c4a595aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is a technique used to break down complex tasks into smaller, more manageable steps, enabling agents to plan and execute tasks efficiently. It involves transforming big tasks into multiple simpler tasks, often utilizing prompting techniques like Chain of Thought or Tree of Thoughts. Thanks for asking!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b7459-48d0-493a-a5b5-c73642afc288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
